// Takes multiple CSVs generated by 'evaluatePerformance' and generates
//    a single CSV that compares all of those results.
// Command line arguments:
// * name1 name2 ... nameN, which will be looked
//   for in e.g. guide_prior_compare/name1.csv
// * --outputName=name: Wite output file to performance_compare/name.csv

var fs = require('fs');
var assert = require('assert');

var performance_compare = __dirname + '/../performance_compare';
var performance_eval = __dirname + '/../performance_eval';

if (!fs.existsSync(performance_compare)) {
	fs.mkdirSync(performance_compare);
}

// Parse args
var opts = require('minimist')(process.argv.slice(2));
var outputName = opts.outputName;
assert(outputName, 'Must define --outputName option');
var names = opts._;

var outfilename = performance_compare + '/' + opts.outputName + '.csv';
var csvfile = fs.openSync(outfilename, 'w');
fs.writeSync(csvfile, 'condition,numParticles,sim,time,avgTime\n');
for (var i = 0; i < names.length; i++) {
	var name = names[i];
	var filename = performance_eval + '/' + name + '.csv';
	var lines = fs.readFileSync(filename).toString().split('\n');
	lines = lines.slice(1, lines.length-1);	// strip header and trailing newline
	for (var j = 0; j < lines.length; j++) {
		fs.writeSync(csvfile, name + ',' + lines[j] + '\n');
	}
}
fs.closeSync(csvfile);

// Copy this file to 'comparison.csv' as well, so we can immediately refresh
//   and view it in Tableau
var cmpname = performance_compare + '/comparison.csv';
require('child_process').execSync('cp ' + outfilename + ' '+ cmpname);

